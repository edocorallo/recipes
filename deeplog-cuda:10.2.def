BootStrap: docker
From: nvidia/cuda:10.2-devel-ubuntu18.04


%post
     	mkdir /container
        cd /container
        mkdir logfiles
        apt-get -y update
        apt-get -y upgrade
        apt-get -y install software-properties-common
        add-apt-repository ppa:deadsnakes/ppa
        apt-get -y update
        apt-get -y install python3.6
        apt-get -y install python3-pip
        apt-get -y install git
        apt-get -y update
        apt-get -y upgrade
        git clone https://github.com/edocorallounibo/DeepLog_no_tensorboard.git
        pip3 install -r DeepLog_no_tensorboard/requirements.txt
        mkdir DeepLog_no_tensorboard/model
        git clone https://github.com/edocorallounibo/drain3.git
	python3 drain3/setup.py
	pip3 install -r drain3/requirements.txt
        cd drain3
        git clone https://github.com/edocorallounibo/parser.git
        pip3 install pandas
        pip3 install scipy

%runscript #WIP
	#!/bin/bash
	if $1=="parse"||"p";then
	#Parsing part
		if $2=="-f";then
			for file in /container/logfiles/storm-frontend/*
				if ![ -f "/container/drain3/parser/results/$file_struct.csv"];then
					do #clustering
						f=${file//'/container/logfile/storm-frontend/'}
						python3 /container/drain3/parser/drain3_parser.py -f $f
					done
				else
					echo "$file seems to be already parsed, if it's a new file to be parsed, please name it differently"
				fi
			for file in /container/Drain3/parser/results/frontend-server/*_struct.csv
				if [![ -f "/container/drain3/parser/results/frontend-server/$file_normal"] && ![ -f "/container/drain3/parser/results/frontend-server/$file_abnormal"]];then
					do #extract sequences
						f=${file//'_struct.csv'}
						f=${f//'results/storm-frontend/'}
						python drain_sequences.py -f $f
					done
				else
					echo "$file seems to be already processed, if it's a new file to be converted in sequences, please name it differently"
				fi
	#Train and Validation sets creation(figure this out ffs)
		else #if $2=="-f"
			for file in /container/logfiles/storm-backend/*
				if ![ -f "/container/drain3/parser/results/$file_struct.csv"];then
					do #clustering
						f=${file//'/container/logfile/storm-backend/'}
						python3 /container/drain3/parser/drain3_parser.py -f $f
					done
				else 
					echo "$file seems to be already parsed, if it's a new file to be parsed, please name it differently"
				fi
			for file in /container/drain3/parser/results/backend-server/*_struct.csv
				if [![ -f "/container/drain3/parser/results/frontend-server/$file_normal"] && ![ -f "/container/drain3/parser/results/frontend-server/$file_abnormal"]];then
					do #extract sequences
						f=${file//'_struct.csv'}
						f=${f//'results/backend-server/'}
						python drain_sequences.py -f $f
					done
				else
					echo "$file seems to be already processed, if it's a new file to be converted in sequences, please name it differently"
				fi
		fi #if $2=="-f"
	else #if $1=="parse"
	#DeepLog part
	fi	#if $1=="parse"

%help
	A container for unprivileged users, build it with the --fakeroot (or -f) option.
	Runs Spell algorithm to parse a log_file into sequences, then runs the LogKey model from DeepLog.
	For references see: LogPai (https://github.com/logpai/logparser)
			    IBM    (https://github.com/IBM/Drain3)
			    DeepLog(https://github.com/wuyifan18/DeepLog)
	One day the parameter model will be implemented, this will increase the overall accuracy

	Usage:
		1st argument:
				-f ,--frontend to parse a frontend file
				-b,--backend   to parse a backend file (incomplete)
		2nd argument:
				log_file the name of the file you want to parse.
				(only storm-linux supported for now, this is still a Work In Progress)

%labels
       	Author edocorallounibo
	Version 0.0.2
